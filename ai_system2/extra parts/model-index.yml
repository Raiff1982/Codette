Models:
  - Name: Codette
    Metadata:
      FLOPs: 5731284192
      Parameters: 23834568
      Epochs: 90
      Batch Size: 32
      Training Data: 
      Training Techniques:
        - RMSProp
        - Weight Decay
        - Gradient Clipping
        - Label Smoothing
      Training Resources: 8x V100 GPUs
      Training Time: 24 hours
      Architecture:
        - Auxiliary Classifier
        - Inception-v3 Module
        - Transformer
        - Self-Attention Mechanism
    Results:
      - Task: Image Classification
        Dataset: ImageNet
        Metrics:
          Top 1 Accuracy: 74.67%
          Top 5 Accuracy: 92.1%
    Paper: 
    Code: 
    Weights: 
    README: 
---
license: mit
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
- deepseek-ai/DeepSeek-R1
- MikeRoz/deepseek-ai_DeepSeek-R1-Distill-Llama-70B-4.25bpw-h6-exl2
- openai-community/gpt2
library_name: transformers
datasets:
- FreedomIntelligence/medical-o1-reasoning-SFT
- cognitivecomputations/dolphin-r1
- PJMixers-Dev/cognitivecomputations_dolphin-r1-reasoning-flash-CustomShareGPT
- HumanLLMs/Human-Like-DPO-Dataset
- Triangle104/HumanLLMs_Human-Like-DPO-Dataset
- DAMO-NLP-SG/multimodal_textbook
- ServiceNow-AI/R1-Distill-SFT
metrics:
- code_eval
- bleurt
- bleu
- accuracy
- bertscore
- brier_score
new_version: deepseek-ai/DeepSeek-V3